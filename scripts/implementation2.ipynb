{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "279c5299-0aee-4c4a-af48-f2a29f5d4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "from rdflib.namespace import FOAF, DC, XSD\n",
    "from SPARQLWrapper import SPARQLWrapper, POST, JSON\n",
    "from urllib.parse import urlparse, urlunparse, quote\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "from typing import List, Set\n",
    "from IPython.display import display\n",
    "import urllib.parse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class IdentifiableEntity:\n",
    "    def __init__(self, id):\n",
    "        self.ids = id if isinstance(id, list) else [id]\n",
    "\n",
    "    def getIds(self):\n",
    "        return self.ids\n",
    "\n",
    "class Person(IdentifiableEntity):\n",
    "    def __init__(self, id, given_name, family_name):\n",
    "        super().__init__(id)\n",
    "        self.given_name = given_name\n",
    "        self.family_name = family_name\n",
    "\n",
    "    def getGivenName(self):\n",
    "        return self.given_name\n",
    "\n",
    "    def getFamilyName(self):\n",
    "        return self.family_name\n",
    "\n",
    " \n",
    "    def getOrcid(self):\n",
    "        \n",
    "        return self.ids[0] if self.ids else None\n",
    "\n",
    "class Publication(IdentifiableEntity):\n",
    "    def __init__(self, id, title, publication_year=None, venue=None, authors=None, publisher=None):\n",
    "        super().__init__(id)\n",
    "        self.title = title\n",
    "        self.publicationYear = publication_year\n",
    "        self.publicationVenue = venue \n",
    "        self.authors = set(authors) if authors else set()\n",
    "        self.citedPublications = []\n",
    "        self.publisher = publisher  # Add this line to include the publisher attribute\n",
    "\n",
    "\n",
    "    def getPublicationYear(self):\n",
    "        return self.publicationYear\n",
    "\n",
    "    def getTitle(self):\n",
    "        return self.title\n",
    "\n",
    "    def getCitedPublications(self):\n",
    "        return self.citedPublications\n",
    "\n",
    "    def getPublicationVenue(self):\n",
    "        return self.publicationVenue\n",
    "\n",
    "    def getAuthors(self):\n",
    "        return self.authors\n",
    "\n",
    "    def getPublisher(self): \n",
    "        return self.publisher\n",
    "\n",
    "    def getVenueType(self):\n",
    "        if isinstance(self.publicationVenue, Venue):\n",
    "            return self.publicationVenue.getVenueType()\n",
    "        return None\n",
    "\n",
    "class Venue(IdentifiableEntity):\n",
    "    def __init__(self, id, title):\n",
    "        super().__init__(id)\n",
    "        self.title = title\n",
    "        self.publisher = None\n",
    "\n",
    "    def getTitle(self):\n",
    "        return self.title\n",
    "\n",
    "    def getPublisher(self):\n",
    "        return self.publisher\n",
    "\n",
    "    def setPublisher(self, publisher):\n",
    "        if isinstance(publisher, Organization):\n",
    "            self.publisher = publisher\n",
    "            \n",
    "    def getVenueType(self):\n",
    "        return \"generic\"  \n",
    "\n",
    "\n",
    "class ProceedingsPaper(Publication):\n",
    "    def __init__(self, id, title, publication_year, publication_venue=None):\n",
    "        super().__init__(id, title, publication_year, publication_venue)\n",
    "\n",
    "class Organization(IdentifiableEntity):\n",
    "    def __init__(self, id, name):\n",
    "        super().__init__(id)\n",
    "        self.name = name\n",
    "\n",
    "    def getName(self):\n",
    "        return self.name\n",
    "\n",
    "class JournalArticle(Publication):\n",
    "    def __init__(self, id, title, publication_year, issue=None, volume=None, publisher=None, publication_venue=None):\n",
    "        super().__init__(id, title, publication_year, publication_venue, publisher=publisher)\n",
    "        self.issue = issue\n",
    "        self.volume = volume\n",
    "\n",
    "\n",
    "    def getIssue(self):\n",
    "        return self.issue\n",
    "\n",
    "    def getVolume(self):\n",
    "        return self.volume\n",
    "\n",
    "class BookChapter(Publication):\n",
    "    def __init__(self, id, title, publication_year, chapter_number, publication_venue=None, publisher_crossref=None):\n",
    "        super().__init__(id, title, publication_year, publication_venue, None, publisher_crossref)\n",
    "        self.chapterNumber = chapter_number\n",
    "\n",
    "    def getChapterNumber(self):\n",
    "        return self.chapterNumber\n",
    "\n",
    "class Journal(Venue):\n",
    "    def getVenueType(self):\n",
    "        return \"journal\"\n",
    "\n",
    "class Book(Venue):\n",
    "    def getVenueType(self):\n",
    "        return \"book\"\n",
    "\n",
    "class Proceedings(Venue):\n",
    "    def __init__(self, id, title, event):\n",
    "        super().__init__(id, title)\n",
    "        self.event = event\n",
    "\n",
    "    def getEvent(self):\n",
    "        return self.event\n",
    "\n",
    "    def getVenueType(self):\n",
    "        return \"conference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "5ff7ed9c-7087-4a0b-a656-d5d1905a99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# Define your namespaces based on your RDF Schema or Ontology\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "CUSTOM = Namespace(\"https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/\")\n",
    "\n",
    "# Inheritance example: TriplestoreQueryProcessor inherits from TriplestoreProcessor\n",
    "class TriplestoreProcessor:\n",
    "    def __init__(self, endpointUrl=None):  # Set a default value for endpointUrl\n",
    "        self.endpointUrl = endpointUrl if endpointUrl is not None else \"\"\n",
    "        \n",
    "    def getEndpointUrl(self):\n",
    "        return self.endpointUrl\n",
    "\n",
    "    def setEndpointUrl(self, url):\n",
    "        self.endpointUrl = url\n",
    "        return True\n",
    "\n",
    "\n",
    "# Association example: TriplestoreDataProcessor has an association with TriplestoreProcessor\n",
    "class TriplestoreDataProcessor(TriplestoreProcessor):\n",
    "    def __init__(self, endpointUrl=\"http://localhost:9999/blazegraph/sparql\"):\n",
    "        super().__init__(endpointUrl)  \n",
    "        self.sparql = SPARQLWrapper(self.endpointUrl)      \n",
    "        self.base_uri = SCHEMA\n",
    "        self.custom_base_uri = CUSTOM\n",
    "        self.graph = Graph()\n",
    "        # Initialize mappings\n",
    "        self.authors_mapping = {}\n",
    "        self.venues_mapping = {}\n",
    "        self.publishers_mapping = {}\n",
    "        self.references_mapping = {}\n",
    "        # Temporary storage for publications if JSON is not yet loaded\n",
    "        self.temp_publications = []\n",
    "        # Flags to check if CSV or JSON data has been loaded\n",
    "        self.csv_loaded = False\n",
    "        self.json_loaded = False\n",
    "    '''\n",
    "    def print_random_publication_details(self):\n",
    "        if not self.temp_publications:\n",
    "            print(\"No publications available.\")\n",
    "            return\n",
    "\n",
    "        # Select a random publication\n",
    "        random_publication = random.choice(self.temp_publications)\n",
    "\n",
    "        # Print details\n",
    "        print(f\"Publication ID: {random_publication.getIds()[0]}\")\n",
    "        print(f\"Title: {random_publication.getTitle()}\")\n",
    "        print(f\"Publication Year: {random_publication.getPublicationYear()}\")\n",
    "        print(f\"Venue Type: {getattr(random_publication, 'venueType', 'Not available')}\")\n",
    "        print(f\"Publication Venue: {getattr(random_publication, 'publicationVenue', 'Not available')}\")\n",
    "\n",
    "\n",
    "\n",
    "    def serialize_and_inspect_rdf_sample(self, num_samples=5):\n",
    "        sample_graph = Graph()\n",
    "        for publication in self.temp_publications[:num_samples]:\n",
    "            rdf_data, _ = self.convert_publication_to_rdf(publication)  # Expecting two return values\n",
    "            sample_graph.parse(data=rdf_data, format='nt')\n",
    "\n",
    "    \n",
    "        # Serialize the sample graph to a string\n",
    "        serialized_data = sample_graph.serialize(format='nt')\n",
    "        print(serialized_data)\n",
    "        return serialized_data\n",
    "    '''\n",
    "    def uploadData(self, path: str):\n",
    "        # Check the file extension and call the appropriate loading function\n",
    "        if path.lower().endswith('.csv'):\n",
    "            success = self.load_csv(path)\n",
    "        elif path.lower().endswith('.json'):\n",
    "            success = self.load_json(path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type. Please provide a .csv or .json file.\")\n",
    "    \n",
    "        # Check if both CSV and JSON data have been loaded\n",
    "        if self.csv_loaded and self.json_loaded:\n",
    "            # Enrich publications with additional information\n",
    "            self.enrich_publications()\n",
    "    \n",
    "            # Convert publications to RDF and add to the graph\n",
    "            self.convert_to_rdf() \n",
    "    \n",
    "            # Upload RDF data to the triplestore\n",
    "            self.upload_rdf_to_triplestore()  \n",
    "    \n",
    "        return success\n",
    "\n",
    "    def load_csv(self, csv_path: str):\n",
    "        self.csv_data = pd.read_csv(csv_path).to_dict(orient='records')  # Store the entire CSV data\n",
    "        df = pd.read_csv(csv_path)\n",
    "    \n",
    "        for index, row in df.iterrows():\n",
    "            # Extracting all fields\n",
    "            publication_id = row['id']\n",
    "            title = row['title']\n",
    "            publication_type = row.get('type', None)\n",
    "            publication_year = row['publication_year']\n",
    "            issue = row.get('issue', None)\n",
    "            volume = row.get('volume', None)\n",
    "            chapter_number = row.get('chapter', None)\n",
    "            publisher_crossref = row.get('publisher', None)\n",
    "            publication_venue = row.get('publication_venue', None)\n",
    "            venue_type = row.get('venue_type', None)\n",
    "            event = row.get('event', None)\n",
    "    \n",
    "            # Determine the type of publication and create corresponding objects\n",
    "            if publication_type == 'journal-article':\n",
    "                publication = JournalArticle(publication_id, title, publication_year, issue, volume, publisher_crossref, publication_venue)\n",
    "            elif publication_type == 'book-chapter':\n",
    "                # Pass publisher_crossref to the BookChapter constructor\n",
    "                publication = BookChapter(publication_id, title, publication_year, chapter_number, publication_venue, publisher_crossref)      \n",
    "            elif publication_type == 'proceedings-paper':\n",
    "                publication = ProceedingsPaper(publication_id, title, publication_year, publication_venue)\n",
    "            else:\n",
    "                # Generic publication object for other types\n",
    "                publication = Publication(publication_id, title, publication_year, publication_venue, None, publisher_crossref)\n",
    "\n",
    "            # Set common properties\n",
    "            publication.venueType = venue_type\n",
    "            publication.event = event\n",
    "    \n",
    "            # Add the publication object to the temporary storage\n",
    "            self.temp_publications.append(publication)\n",
    "    \n",
    "        self.csv_loaded = True\n",
    "        return True\n",
    "\n",
    "       \n",
    "\n",
    "    def load_json(self, json_path: str):\n",
    "        with open(json_path, 'r') as file:\n",
    "            self.json_data = json.load(file)  # Load JSON data into an instance variable\n",
    "    \n",
    "        # Processing authors\n",
    "        for publication_doi, authors_list in self.json_data['authors'].items():\n",
    "            for author_info in authors_list:\n",
    "                author_id = author_info['orcid']\n",
    "                given_name = author_info['given']\n",
    "                family_name = author_info['family']\n",
    "                author = Person(author_id, given_name, family_name)\n",
    "                self.authors_mapping[author_id] = author\n",
    "    \n",
    "        # Processing venues\n",
    "        # Just store the mapping for now, we'll connect venues to publications later\n",
    "        self.venues_mapping = self.json_data['venues_id']\n",
    "    \n",
    "        # Processing publishers\n",
    "        for publisher_id, publisher_info in self.json_data['publishers'].items():\n",
    "            publisher = Organization(publisher_info['id'], publisher_info['name'])\n",
    "            self.publishers_mapping[publisher_id] = publisher\n",
    "    \n",
    "        # Processing references\n",
    "        self.references_mapping = self.json_data['references']\n",
    "\n",
    "        # Handling JSON-only DOIs\n",
    "        json_dois = set(self.json_data['authors'].keys()) | set(self.json_data['venues_id'].keys())\n",
    "        existing_dois = {pub.getIds()[0] for pub in self.temp_publications}\n",
    "        json_only_dois = json_dois - existing_dois\n",
    "        for doi in json_only_dois:\n",
    "            title = \"Title not provided\"  # Placeholder title\n",
    "            publication = Publication(doi, title)\n",
    "            self.temp_publications.append(publication)\n",
    "\n",
    "        # Debugging: Print publishers_mapping to verify its contents\n",
    "        #for crossref, publisher in self.publishers_mapping.items():\n",
    "            #print(f\"Crossref ID: {crossref}, Publisher: {publisher.getName()}\")\n",
    "\n",
    "        \n",
    "        self.json_loaded = True\n",
    "        return True\n",
    "        \n",
    "            \n",
    "        # If CSV data has been loaded, enrich the publication data\n",
    "        if self.csv_loaded:\n",
    "            self.enrich_publications()\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "    def enrich_publications(self):\n",
    "        for publication in self.temp_publications:\n",
    "            doi = publication.getIds()[0]\n",
    "    \n",
    "            # Debugging: Print publication type and DOI\n",
    "            #print(f\"Processing DOI: {doi}, Type: {type(publication).__name__}, Initial Publisher: {publication.getPublisher()}\")\n",
    "    \n",
    "            # Connect authors based on DOI\n",
    "            authors_list = [Person(author['orcid'], author['given'], author['family'])\n",
    "                            for author in self.json_data['authors'].get(doi, [])]\n",
    "            publication.authors.update(authors_list)\n",
    "    \n",
    "            # Connect venues based on DOI and store the venue ID (ISSN/ISBN)\n",
    "            venue_ids = self.json_data['venues_id'].get(doi, [])\n",
    "            if venue_ids:\n",
    "                # Assuming the first venue ID is the primary one\n",
    "                venue_id = venue_ids[0]\n",
    "                venue_title = self.json_data['venues_id'].get(venue_id, {}).get('title')\n",
    "                if venue_title:\n",
    "                    publication.publicationVenue = venue_title\n",
    "                # Store the venue ID (ISSN/ISBN) in the publication object\n",
    "                publication.venueID = venue_id\n",
    "\n",
    "    \n",
    "            # Connect references based on DOI\n",
    "            publication.citedPublications = self.json_data['references'].get(doi, [])\n",
    "    \n",
    "            # Initialize publisher_crossref variable\n",
    "            publisher_crossref = None\n",
    "    \n",
    "            # Retrieve publisher information from publication object\n",
    "            publisher_info = publication.getPublisher()\n",
    "            if publisher_info:\n",
    "                # Check if publisher is an Organization object (from JSON)\n",
    "                if isinstance(publisher_info, Organization):\n",
    "                    publisher_crossref = publisher_info.ids[0]  # Assuming the first ID is Crossref\n",
    "                else:\n",
    "                    # If publisher_info is already a Crossref ID (string)\n",
    "                    publisher_crossref = publisher_info\n",
    "    \n",
    "            # If no publisher in publication object, check JSON with DOI as a key\n",
    "            if not publisher_crossref:\n",
    "                publisher_info_json = self.json_data['publishers'].get(doi)\n",
    "                if publisher_info_json:\n",
    "                    publisher_crossref = publisher_info_json['id']\n",
    "    \n",
    "            # Update the publication's publisher attribute to store only the Crossref ID\n",
    "            publication.publisher = publisher_crossref\n",
    "    \n",
    "            # Debugging: Print final publisher info\n",
    "            #print(f\"Final Publisher for {doi}: {publication.getPublisher()}\")\n",
    "    \n",
    "            # Additional logic for ProceedingsPaper\n",
    "            if isinstance(publication, ProceedingsPaper) and hasattr(publication, 'event'):\n",
    "                publication.event = self.json_data['events'].get(doi, 'Unknown Event')\n",
    "    \n",
    "            # Attempt to fill in missing titles with data from the CSV if loaded\n",
    "            if self.csv_loaded and not publication.getTitle():\n",
    "                csv_entry = next((row for row in self.csv_data if row['id'] == doi), None)\n",
    "                if csv_entry:\n",
    "                    publication.title = csv_entry['title']\n",
    "\n",
    "\n",
    "    def sanitize_uri(self, uri: str) -> str:\n",
    "        \"\"\"\n",
    "        Ensures that the URI is valid and properly encoded for RDF and SPARQL usage.\n",
    "        Also handles DOIs, ORCIDs, ISSNs, ISBNs, and Crossref IDs by appending appropriate resolver URLs.\n",
    "        \"\"\"\n",
    "        # Prepend the DOI resolver URL if it's a DOI\n",
    "        if uri.startswith('doi:'):\n",
    "            uri = 'https://doi.org/' + uri[4:]  # Remove the 'doi:' part and prepend the resolver URL\n",
    "        \n",
    "        # Prepend the ORCID URL if it's an ORCID identifier\n",
    "        elif uri.startswith('0000-'):\n",
    "            uri = 'https://orcid.org/' + uri\n",
    "        \n",
    "        # Handle venue names or other arbitrary strings\n",
    "        parsed_uri = urlparse(uri)\n",
    "        if not (parsed_uri.scheme and parsed_uri.netloc):\n",
    "            # URL encode the string to make it a valid URI\n",
    "            encoded_uri = quote(uri, safe='')\n",
    "            # Prepend the SCHEMA namespace as the base URI\n",
    "            uri = str(SCHEMA[encoded_uri])\n",
    "        \n",
    "        # Prepend a base URI for ISSNs\n",
    "        elif uri.startswith('issn:'):\n",
    "            uri = 'http://purl.org/issn/' + uri[5:]  # Remove the 'issn:' part and prepend the base URI\n",
    "        \n",
    "        # Prepend a base URI for ISBNs\n",
    "        elif uri.startswith('isbn:'):\n",
    "            uri = 'https://www.isbn-international.org/identifier/' + uri[5:]  # Remove the 'isbn:' part and prepend the base URI\n",
    "        \n",
    "        # Prepend a base URI for Crossref IDs\n",
    "        elif uri.startswith('crossref:'):\n",
    "            crossref_id = uri[9:]  # Extract the Crossref ID\n",
    "            # Directly build the URI without double encoding\n",
    "            uri = 'https://api.crossref.org/works/' + quote(crossref_id)\n",
    "        \n",
    "        # Check if a valid URI is already formed\n",
    "        parsed_uri = urlparse(uri)\n",
    "        if parsed_uri.scheme and parsed_uri.netloc:\n",
    "            # URI is valid, proceed to encode the components\n",
    "            encoded_path = quote(parsed_uri.path, safe='/')\n",
    "            encoded_query = quote(parsed_uri.query, safe='=&?/')\n",
    "            encoded_fragment = quote(parsed_uri.fragment, safe='')\n",
    "        \n",
    "            # Rebuild the URI with the encoded components\n",
    "            return urlunparse((\n",
    "                parsed_uri.scheme,\n",
    "                parsed_uri.netloc,\n",
    "                encoded_path,\n",
    "                parsed_uri.params,\n",
    "                encoded_query,\n",
    "                encoded_fragment\n",
    "            ))\n",
    "        else:\n",
    "            # If the scheme and netloc are missing after the checks, the URI cannot be validated\n",
    "            raise ValueError(f\"Invalid URI: {uri}\")\n",
    "            \n",
    "        \n",
    "    def convert_publication_to_rdf(self, publication):\n",
    "        # Create a new graph for the individual publication\n",
    "        graph = Graph()\n",
    "        pub_uri = URIRef(self.sanitize_uri(str(publication.getIds()[0])))\n",
    "        \n",
    "        # Add common properties with schema.org vocabulary\n",
    "        graph.add((pub_uri, RDF.type, SCHEMA.ScholarlyArticle))\n",
    "        graph.add((pub_uri, SCHEMA.name, Literal(publication.getTitle())))\n",
    "    \n",
    "        # Add the publication year, only if it's not None\n",
    "        if publication.getPublicationYear() is not None:\n",
    "            graph.add((pub_uri, SCHEMA.datePublished, Literal(str(publication.getPublicationYear()), datatype=XSD.gYear)))\n",
    "            \n",
    "        # Add authors to the graph\n",
    "        for author in publication.getAuthors():\n",
    "            author_uri = URIRef(self.sanitize_uri(author.getOrcid()))\n",
    "            graph.add((author_uri, RDF.type, SCHEMA.Person))\n",
    "            graph.add((author_uri, SCHEMA.givenName, Literal(author.getGivenName())))\n",
    "            graph.add((author_uri, SCHEMA.familyName, Literal(author.getFamilyName())))\n",
    "            graph.add((pub_uri, SCHEMA.author, author_uri))\n",
    "        \n",
    "        # Handle publisher information\n",
    "        publisher_crossref = publication.getPublisher()\n",
    "        if publisher_crossref and publisher_crossref in self.publishers_mapping:\n",
    "            # Decode the Crossref ID\n",
    "            decoded_crossref = urllib.parse.unquote(publisher_crossref)\n",
    "            publisher = self.publishers_mapping[decoded_crossref]\n",
    "            publisher_uri = URIRef(self.sanitize_uri(decoded_crossref)) \n",
    "            # Get the publisher object from the mapping\n",
    "            publisher = self.publishers_mapping[publisher_crossref]\n",
    "            #print(f\"Found publisher for {publisher_crossref}: {publisher.getName()}\")  # Debugging statement\n",
    "            publisher_uri = URIRef(self.sanitize_uri(publisher_crossref))  # Sanitize the Crossref ID\n",
    "            # Add RDF triples for the publisher\n",
    "            graph.add((publisher_uri, RDF.type, SCHEMA.Organization))\n",
    "            graph.add((publisher_uri, SCHEMA.name, Literal(publisher.getName())))\n",
    "            # Link the publication to its publisher\n",
    "            graph.add((pub_uri, SCHEMA.publisher, publisher_uri))\n",
    "        \n",
    "\n",
    "        # Handle venue type information\n",
    "        venue_type = getattr(publication, 'venueType', None)\n",
    "        if venue_type:\n",
    "            graph.add((pub_uri, CUSTOM.venueType, Literal(venue_type)))  # Add venue type as a literal\n",
    "\n",
    "        # Handle venue ID (ISSN/ISBN)\n",
    "        if hasattr(publication, 'venueID') and publication.venueID:\n",
    "            venue_uri = URIRef(self.sanitize_uri(publication.venueID))\n",
    "            graph.add((venue_uri, RDF.type, SCHEMA.Periodical))  # Or appropriate type\n",
    "            graph.add((pub_uri, SCHEMA.isPartOf, venue_uri))  # Link publication to its venue\n",
    "        \n",
    "        # Handle publication venue information correctly\n",
    "        pub_venue = publication.getPublicationVenue()\n",
    "        if pub_venue:\n",
    "            # You can either add it as a URI (if it's a resolvable URL) or as a literal\n",
    "            # To add as a literal:\n",
    "            graph.add((pub_uri, CUSTOM.publicationVenue, Literal(pub_venue)))\n",
    "        \n",
    "        # Handle specific properties based on publication type\n",
    "        if isinstance(publication, JournalArticle):\n",
    "            # Add journal-specific properties such as volume and issue\n",
    "            if publication.getVolume():\n",
    "                graph.add((pub_uri, SCHEMA.volumeNumber, Literal(publication.getVolume())))\n",
    "            if publication.getIssue():\n",
    "                graph.add((pub_uri, SCHEMA.issueNumber, Literal(publication.getIssue())))\n",
    "    \n",
    "        elif isinstance(publication, BookChapter):\n",
    "            # Add book chapter-specific properties such as chapter number\n",
    "            if publication.getChapterNumber() is not None:\n",
    "                graph.add((pub_uri, SCHEMA.chapterNumber, Literal(publication.getChapterNumber())))\n",
    "    \n",
    "        elif isinstance(publication, ProceedingsPaper):\n",
    "            # Add proceedings-specific properties (e.g., event)\n",
    "            if publication.getEvent() is not None:\n",
    "                graph.add((pub_uri, SCHEMA.event, Literal(publication.getEvent())))\n",
    "    \n",
    "        # Add cited publications\n",
    "        for cited_doi in publication.getCitedPublications():\n",
    "            cited_uri = URIRef(self.sanitize_uri(cited_doi))\n",
    "            graph.add((pub_uri, SCHEMA.citation, cited_uri))\n",
    "    \n",
    "        # Serialize the individual publication graph to N-Triples\n",
    "        rdf_data = graph.serialize(format='nt')\n",
    "        triple_count = len(graph)\n",
    "        return rdf_data, triple_count\n",
    "\n",
    "\n",
    "    def save_graph_to_file(self, graph, file_path):\n",
    "        # Serialize the entire graph to N-Triples\n",
    "        rdf_data = graph.serialize(format='nt')\n",
    "        \n",
    "        # Save to a text file\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(rdf_data)\n",
    "    \n",
    "        print(f\"Saved RDF data to {file_path}\")\n",
    "\n",
    "        \n",
    "    def convert_to_rdf(self):\n",
    "        \"\"\"\n",
    "        Converts the enriched publication objects to RDF triples and adds them to the graph.\n",
    "        \"\"\"\n",
    "        for publication in self.temp_publications:\n",
    "            # Use the convert_publication_to_rdf method to convert each publication\n",
    "            rdf_data, triple_count = self.convert_publication_to_rdf(publication)\n",
    "            # Parse the serialized RDF data into the main graph\n",
    "            self.graph.parse(data=rdf_data, format='nt')\n",
    "        \n",
    "        # Print the total number of triples for verification\n",
    "        #print(f\"Total number of triples in the graph: {len(self.graph)}\")\n",
    "\n",
    "        # Once the RDF graph is complete, upload it to the triplestore\n",
    "        self.upload_rdf_to_triplestore()\n",
    "\n",
    "\n",
    "\n",
    "    def upload_rdf_to_triplestore(self):\n",
    "        try:\n",
    "            # Serialize the graph in NTriples format\n",
    "            serialized_graph = self.graph.serialize(format='nt')\n",
    "\n",
    "            # Print out the serialized graph to inspect it\n",
    "            #print(serialized_graph)\n",
    "\n",
    "            # Initialize SPARQLWrapper with the endpoint URL\n",
    "            sparql = SPARQLWrapper('http://localhost:9999/blazegraph/sparql')\n",
    "\n",
    "            # Set the request method to POST\n",
    "            sparql.setMethod(POST)\n",
    "\n",
    "            # Set the query for SPARQLWrapper\n",
    "            sparql.setQuery(f'INSERT DATA {{ {serialized_graph} }}')\n",
    "\n",
    "            # Perform the query\n",
    "            response = sparql.query()\n",
    "\n",
    "            # Handle the response\n",
    "            #print(f\"Response from the triplestore: {response.response.read()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during RDF upload: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "class TriplestoreQueryProcessor(TriplestoreProcessor):\n",
    "    def __init__(self, endpointUrl=None):\n",
    "        super().__init__(endpointUrl)\n",
    "        self.sparql = SPARQLWrapper(self.endpointUrl if self.endpointUrl else \"http://localhost:9999/blazegraph/sparql\")\n",
    "        \n",
    "    def run_query(self, query):\n",
    "        try:\n",
    "            self.sparql.setQuery(query)\n",
    "            self.sparql.setReturnFormat(JSON)\n",
    "            results = self.sparql.query().convert()\n",
    "\n",
    "            # Process the results to have cleaner column names\n",
    "            processed_results = []\n",
    "            for result in results[\"results\"][\"bindings\"]:\n",
    "                processed_row = {}\n",
    "                for key, value in result.items():\n",
    "                    processed_row[key] = value.get('value', None)  # Get the 'value' for each key\n",
    "                processed_results.append(processed_row)\n",
    "\n",
    "            return pd.DataFrame(processed_results)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def format_identifier(identifier):\n",
    "        if identifier.startswith(\"issn:\"):\n",
    "            formatted_identifier = identifier.replace(\"issn:\", \"issn%253A\")\n",
    "        elif identifier.startswith(\"isbn:\"):\n",
    "            formatted_identifier = identifier.replace(\"isbn:\", \"isbn%253A\")\n",
    "        else:\n",
    "            formatted_identifier = identifier  # Or handle other cases as needed\n",
    "        return formatted_identifier\n",
    "\n",
    "    @staticmethod\n",
    "    def format_dois(dois):\n",
    "        if not isinstance(dois, list):\n",
    "            dois = [dois]\n",
    "    \n",
    "        formatted_dois = []\n",
    "        for doi in dois:\n",
    "            if doi.startswith(\"doi:\"):\n",
    "                formatted_doi = f\"<https://doi.org/{doi[4:]}>\"\n",
    "            elif \"https://doi.org/\" not in doi:\n",
    "                formatted_doi = f\"<https://doi.org/{doi}>\"\n",
    "            else:\n",
    "                formatted_doi = f\"<{doi}>\"\n",
    "            formatted_dois.append(formatted_doi)\n",
    "    \n",
    "        return formatted_dois\n",
    "\n",
    "    @staticmethod\n",
    "    def format_crossref_publisher_id(publisher_id):\n",
    "        if publisher_id.startswith(\"crossref:\"):\n",
    "            formatted_id = publisher_id.split(':')[1]\n",
    "        else:\n",
    "            formatted_id = publisher_id  # Or handle other cases as needed\n",
    "        return f\"https://api.crossref.org/works/{formatted_id}\"\n",
    "    \n",
    "    def getPublicationsPublishedInYear(self, year):  # Renamed method\n",
    "        query = f\"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        PREFIX custom: <https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/>\n",
    "        \n",
    "        SELECT ?id ?title \n",
    "               (GROUP_CONCAT(DISTINCT ?publicationVenue; separator=\", \") AS ?publicationVenues) \n",
    "               (GROUP_CONCAT(DISTINCT CONCAT(?givenName, \" \", ?familyName); separator=\", \") AS ?authors)\n",
    "               (GROUP_CONCAT(DISTINCT STR(?citedPublication); separator=\", \") AS ?citedPublications)\n",
    "               (SAMPLE(?publisherName) AS ?publisherNames) (SAMPLE(?crossrefID) AS ?crossrefIDs)\n",
    "               (SAMPLE(?venueType) AS ?venueTypes) (SAMPLE(?issue) AS ?issues) \n",
    "               (SAMPLE(?volume) AS ?volumes) (SAMPLE(?chapter) AS ?chapterNumbers) \n",
    "               (SAMPLE(?event) AS ?events)\n",
    "        WHERE {{\n",
    "          ?id schema:datePublished \"{year}\"^^<http://www.w3.org/2001/XMLSchema#gYear> .\n",
    "          ?id schema:name ?title .\n",
    "        \n",
    "          OPTIONAL {{ ?id custom:publicationVenue ?publicationVenue . }}\n",
    "          OPTIONAL {{ ?id custom:venueType ?venueType . }}\n",
    "        \n",
    "          OPTIONAL {{\n",
    "            ?id schema:author ?author .\n",
    "            ?author schema:familyName ?familyName .\n",
    "            ?author schema:givenName ?givenName .\n",
    "          }}\n",
    "        \n",
    "          OPTIONAL {{\n",
    "            ?id schema:citation ?citedPublication .\n",
    "          }}\n",
    "        \n",
    "          OPTIONAL {{\n",
    "            ?id schema:publisher ?publisher .\n",
    "            ?publisher schema:name ?publisherName .\n",
    "            BIND(REPLACE(STRAFTER(STR(?publisher), \"schema.org/\"), \"%253A\", \":\") AS ?crossrefID)\n",
    "          }}\n",
    "        \n",
    "          OPTIONAL {{ ?id schema:issueNumber ?issue . }}\n",
    "          OPTIONAL {{ ?id schema:volumeNumber ?volume . }}\n",
    "          OPTIONAL {{ ?id schema:chapterNumber ?chapter . }}\n",
    "          OPTIONAL {{ ?id schema:event ?event . }}\n",
    "        }}\n",
    "        GROUP BY ?id ?title\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "    def getPublicationsByAuthorId(self, author_id):  # Renamed method\n",
    "        query = f\"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        PREFIX custom: <https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/>\n",
    "        \n",
    "        SELECT ?id ?title \n",
    "               (GROUP_CONCAT(DISTINCT ?publicationVenue; separator=\", \") AS ?publicationVenues) \n",
    "               (GROUP_CONCAT(DISTINCT CONCAT(?givenName, \" \", ?familyName); separator=\", \") AS ?authors)\n",
    "               (GROUP_CONCAT(DISTINCT STR(?citedPublication); separator=\", \") AS ?citedPublications)\n",
    "               (SAMPLE(?publisherName) AS ?publisherNames) (SAMPLE(?crossrefID) AS ?crossrefIDs)\n",
    "               (SAMPLE(?venueType) AS ?venueTypes) (SAMPLE(?issue) AS ?issues) \n",
    "               (SAMPLE(?volume) AS ?volumes) (SAMPLE(?chapter) AS ?chapterNumbers) \n",
    "               (SAMPLE(?event) AS ?events)\n",
    "        WHERE {{\n",
    "          ?id schema:author <https://orcid.org/{author_id}> .\n",
    "          ?id schema:name ?title .\n",
    "        \n",
    "          OPTIONAL {{ ?id custom:publicationVenue ?publicationVenue . }}\n",
    "          OPTIONAL {{ ?id custom:venueType ?venueType . }}\n",
    "        \n",
    "          OPTIONAL {{\n",
    "            ?id schema:author ?author .\n",
    "            ?author schema:familyName ?familyName .\n",
    "            ?author schema:givenName ?givenName .\n",
    "          }}\n",
    "        \n",
    "          OPTIONAL {{\n",
    "            ?id schema:citation ?citedPublication .\n",
    "          }}\n",
    "        \n",
    "          OPTIONAL {{\n",
    "            ?id schema:publisher ?publisher .\n",
    "            ?publisher schema:name ?publisherName .\n",
    "            BIND(REPLACE(STRAFTER(STR(?publisher), \"schema.org/\"), \"%253A\", \":\") AS ?crossrefID)\n",
    "          }}\n",
    "        \n",
    "          OPTIONAL {{ ?id schema:issueNumber ?issue . }}\n",
    "          OPTIONAL {{ ?id schema:volumeNumber ?volume . }}\n",
    "          OPTIONAL {{ ?id schema:chapterNumber ?chapter . }}\n",
    "          OPTIONAL {{ ?id schema:event ?event . }}\n",
    "        }}\n",
    "        GROUP BY ?id ?title\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "    def getMostCitedPublication(self):  # Renamed method\n",
    "        query = \"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        PREFIX custom: <https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/>\n",
    "        \n",
    "        SELECT ?id ?title \n",
    "               (COUNT(DISTINCT ?citedBy) AS ?citationCount)\n",
    "               (GROUP_CONCAT(DISTINCT ?publicationVenue; separator=\", \") AS ?publicationVenues) \n",
    "               (GROUP_CONCAT(DISTINCT CONCAT(?givenName, \" \", ?familyName); separator=\", \") AS ?authors)\n",
    "               (SAMPLE(?publisherName) AS ?publisherNames) (SAMPLE(?crossrefID) AS ?crossrefIDs)\n",
    "               (SAMPLE(?venueType) AS ?venueTypes) (SAMPLE(?issue) AS ?issues) \n",
    "               (SAMPLE(?volume) AS ?volumes) (SAMPLE(?chapter) AS ?chapterNumbers) \n",
    "               (SAMPLE(?event) AS ?events)\n",
    "        WHERE {\n",
    "          ?id schema:name ?title .\n",
    "\n",
    "          OPTIONAL { ?id custom:publicationVenue ?publicationVenue . }\n",
    "          OPTIONAL { ?id custom:venueType ?venueType . }\n",
    "\n",
    "          OPTIONAL {\n",
    "            ?id schema:author ?author .\n",
    "            ?author schema:familyName ?familyName .\n",
    "            ?author schema:givenName ?givenName .\n",
    "          }\n",
    "\n",
    "          OPTIONAL {\n",
    "            ?citedBy schema:citation ?id .\n",
    "          }\n",
    "\n",
    "          OPTIONAL {\n",
    "            ?id schema:publisher ?publisher .\n",
    "            ?publisher schema:name ?publisherName .\n",
    "            BIND(REPLACE(STRAFTER(STR(?publisher), \"schema.org/\"), \"%253A\", \":\") AS ?crossrefID)\n",
    "          }\n",
    "\n",
    "          OPTIONAL { ?id schema:issueNumber ?issue . }\n",
    "          OPTIONAL { ?id schema:volumeNumber ?volume . }\n",
    "          OPTIONAL { ?id schema:chapterNumber ?chapter . }\n",
    "          OPTIONAL { ?id schema:event ?event . }\n",
    "        }\n",
    "        GROUP BY ?id ?title\n",
    "        ORDER BY DESC(?citationCount)\n",
    "        LIMIT1\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "    def getMostCitedVenue(self):\n",
    "        query = \"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        PREFIX custom: <https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/>\n",
    "        \n",
    "        SELECT ?venue\n",
    "               (COUNT(DISTINCT ?citedBy) AS ?totalCitations)\n",
    "               (SAMPLE(?venueType) AS ?venueTypes)\n",
    "               (SAMPLE(?publisherName) AS ?publisherNames)\n",
    "               (SAMPLE(?crossrefID) AS ?crossrefIDs)\n",
    "        WHERE {\n",
    "          ?publication custom:publicationVenue ?venue .\n",
    "          OPTIONAL { ?publication custom:venueType ?venueType . }\n",
    "          \n",
    "          OPTIONAL {\n",
    "            ?citedBy schema:citation ?publication .\n",
    "          }\n",
    "\n",
    "          OPTIONAL {\n",
    "            ?publication schema:publisher ?publisher .\n",
    "            ?publisher schema:name ?publisherName .\n",
    "            BIND(REPLACE(STRAFTER(STR(?publisher), \"schema.org/\"), \"%253A\", \":\") AS ?crossrefID)\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?venue\n",
    "        ORDER BY DESC(?totalCitations)\n",
    "        LIMIT1\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "    def getVenuesByPublisherId(self, publisher_id):\n",
    "        formatted_publisher_id = self.format_crossref_publisher_id(publisher_id)\n",
    "        query = f\"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        SELECT ?venue\n",
    "        WHERE {{\n",
    "          ?publication schema:publisher <{formatted_publisher_id}> .\n",
    "          ?publication schema:isPartOf ?venue .\n",
    "        }}\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "    def getPublicationInVenue(self, venue_identifier):\n",
    "        formatted_venue_identifier = self.format_identifier(venue_identifier)  # Format the identifier\n",
    "        query = f\"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        PREFIX custom: <https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/>\n",
    "        \n",
    "        SELECT ?id ?title \n",
    "               (GROUP_CONCAT(DISTINCT ?publicationVenue; separator=\", \") AS ?publicationVenues) \n",
    "               (GROUP_CONCAT(DISTINCT CONCAT(?givenName, \" \", ?familyName); separator=\", \") AS ?authors)\n",
    "               (GROUP_CONCAT(DISTINCT STR(?citedPublication); separator=\", \") AS ?citedPublications)\n",
    "               (SAMPLE(?publisherName) AS ?publisherNames) (SAMPLE(?crossrefID) AS ?crossrefIDs)\n",
    "               (SAMPLE(?venueType) AS ?venueTypes) (SAMPLE(?issue) AS ?issues) \n",
    "               (SAMPLE(?volume) AS ?volumes) (SAMPLE(?chapter) AS ?chapterNumbers) \n",
    "               (SAMPLE(?event) AS ?events)\n",
    "        WHERE {{\n",
    "          ?id custom:publicationVenue ?publicationVenue .\n",
    "          ?id schema:isPartOf <http://schema.org/{formatted_venue_identifier}> .\n",
    "          ?id schema:name ?title .\n",
    "        \n",
    "          OPTIONAL {{ ?id custom:venueType ?venueType . }}\n",
    "        \n",
    "          OPTIONAL {{\n",
    "            ?id schema:author ?author .\n",
    "            ?author schema:familyName ?familyName .\n",
    "            ?author schema:givenName ?givenName .\n",
    "          }}\n",
    "        \n",
    "          OPTIONAL {{\n",
    "            ?id schema:citation ?citedPublication .\n",
    "          }}\n",
    "        \n",
    "          OPTIONAL {{\n",
    "            ?id schema:publisher ?publisher .\n",
    "            ?publisher schema:name ?publisherName .\n",
    "            BIND(REPLACE(STRAFTER(STR(?publisher), \"schema.org/\"), \"%253A\", \":\") AS ?crossrefID)\n",
    "          }}\n",
    "        \n",
    "          OPTIONAL {{ ?id schema:issueNumber ?issue . }}\n",
    "          OPTIONAL {{ ?id schema:volumeNumber ?volume . }}\n",
    "          OPTIONAL {{ ?id schema:chapterNumber ?chapter . }}\n",
    "          OPTIONAL {{ ?id schema:event ?event . }}\n",
    "        }}\n",
    "        GROUP BY ?id ?title\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "    def getJournalArticlesInIssue(self, identifier, volume, issue):\n",
    "        formatted_identifier = self.format_identifier(identifier)  # Format the ISSN or ISBN\n",
    "        query = f\"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        PREFIX custom: <https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/>\n",
    "        \n",
    "        SELECT ?id ?title \n",
    "               (SAMPLE(?publicationYear) AS ?publicationYears)\n",
    "               (SAMPLE(?publisherName) AS ?publisherNames) \n",
    "               (SAMPLE(?crossrefID) AS ?crossrefIDs)\n",
    "               (SAMPLE(?publicationVenue) AS ?publicationVenues)\n",
    "               (SAMPLE(?venueType) AS ?venueTypes)\n",
    "        WHERE {{\n",
    "          ?id schema:isPartOf <http://schema.org/{formatted_identifier}> .\n",
    "          ?id schema:volumeNumber \"{volume}\"^^<http://www.w3.org/2001/XMLSchema#string> .\n",
    "          ?id schema:issueNumber \"{issue}\"^^<http://www.w3.org/2001/XMLSchema#string> .\n",
    "          ?id schema:name ?title .\n",
    "        \n",
    "          OPTIONAL {{ ?id schema:datePublished ?publicationYear . }}\n",
    "          OPTIONAL {{ ?id custom:publicationVenue ?publicationVenue . }}\n",
    "          OPTIONAL {{ ?id custom:venueType ?venueType . }}\n",
    "        \n",
    "          OPTIONAL {{\n",
    "            ?id schema:publisher ?publisher .\n",
    "            ?publisher schema:name ?publisherName .\n",
    "            BIND(REPLACE(STRAFTER(STR(?publisher), \"schema.org/\"), \"%253A\", \":\") AS ?crossrefID)\n",
    "          }}\n",
    "        }}\n",
    "        GROUP BY ?id ?title\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "\n",
    "    def getJournalArticlesInVolume(self, identifier, volume):\n",
    "        formatted_identifier = self.format_identifier(identifier)  # Format the ISSN or ISBN\n",
    "        query = f\"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        PREFIX custom: <https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/>\n",
    "        \n",
    "        SELECT ?id ?title \n",
    "               (SAMPLE(?publicationYear) AS ?publicationYears)\n",
    "               (SAMPLE(?publisherName) AS ?publisherNames) \n",
    "               (SAMPLE(?crossrefID) AS ?crossrefIDs)\n",
    "               (SAMPLE(?publicationVenue) AS ?publicationVenues)\n",
    "               (SAMPLE(?venueType) AS ?venueTypes)\n",
    "        WHERE {{\n",
    "          ?id schema:isPartOf <http://schema.org/{formatted_identifier}> .\n",
    "          ?id schema:volumeNumber \"{volume}\"^^<http://www.w3.org/2001/XMLSchema#string> .\n",
    "          ?id schema:name ?title .\n",
    "        \n",
    "          OPTIONAL {{ ?id schema:datePublished ?publicationYear . }}\n",
    "          OPTIONAL {{ ?id custom:publicationVenue ?publicationVenue . }}\n",
    "          OPTIONAL {{ ?id custom:venueType ?venueType . }}\n",
    "        \n",
    "          OPTIONAL {{\n",
    "            ?id schema:publisher ?publisher .\n",
    "            ?publisher schema:name ?publisherName .\n",
    "            BIND(REPLACE(STRAFTER(STR(?publisher), \"schema.org/\"), \"%253A\", \":\") AS ?crossrefID)\n",
    "          }}\n",
    "        }}\n",
    "        GROUP BY ?id ?title\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "    def getJournalArticlesInJournal(self, identifier):\n",
    "        formatted_identifier = self.format_identifier(identifier)  # Format the ISSN or ISBN\n",
    "        query = f\"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        PREFIX custom: <https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/>\n",
    "        \n",
    "        SELECT ?id ?title \n",
    "               (SAMPLE(?publicationYear) AS ?publicationYears)\n",
    "               (SAMPLE(?issue) AS ?issues) \n",
    "               (SAMPLE(?volume) AS ?volumes) \n",
    "               (SAMPLE(?publisherName) AS ?publisherNames) \n",
    "               (SAMPLE(?crossrefID) AS ?crossrefIDs)\n",
    "               (SAMPLE(?publicationVenue) AS ?publicationVenues)\n",
    "               (SAMPLE(?venueType) AS ?venueTypes)\n",
    "        WHERE {{\n",
    "          ?id schema:isPartOf <http://schema.org/{formatted_identifier}> .\n",
    "          ?id schema:name ?title .\n",
    "        \n",
    "          OPTIONAL {{ ?id schema:datePublished ?publicationYear . }}\n",
    "          OPTIONAL {{ ?id custom:publicationVenue ?publicationVenue . }}\n",
    "          OPTIONAL {{ ?id custom:venueType ?venueType . }}\n",
    "        \n",
    "          OPTIONAL {{\n",
    "            ?id schema:publisher ?publisher .\n",
    "            ?publisher schema:name ?publisherName .\n",
    "            BIND(REPLACE(STRAFTER(STR(?publisher), \"schema.org/\"), \"%253A\", \":\") AS ?crossrefID)\n",
    "          }}\n",
    "\n",
    "          OPTIONAL {{ ?id schema:issueNumber ?issue . }}\n",
    "          OPTIONAL {{ ?id schema:volumeNumber ?volume . }}\n",
    "        }}\n",
    "        GROUP BY ?id ?title\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "    def getProceedingsByEvent(self, eventName):\n",
    "        query = f\"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        PREFIX custom: <https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/>\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "        SELECT ?id ?title \n",
    "               (SAMPLE(?publicationYear) AS ?publicationYears)\n",
    "               (SAMPLE(?issue) AS ?issues) \n",
    "               (SAMPLE(?volume) AS ?volumes) \n",
    "               (SAMPLE(?publisherName) AS ?publisherNames) \n",
    "               (SAMPLE(?crossrefID) AS ?crossrefIDs)\n",
    "               (SAMPLE(?publicationVenue) AS ?publicationVenues)\n",
    "               (SAMPLE(?venueType) AS ?venueTypes)\n",
    "        WHERE {{\n",
    "          ?id schema:event ?event .\n",
    "          FILTER CONTAINS(LCASE(STR(?event)), LCASE(STR(\"{eventName}\")))\n",
    "          ?id schema:name ?title .\n",
    "\n",
    "          OPTIONAL {{ ?id schema:datePublished ?publicationYear . }}\n",
    "          OPTIONAL {{ ?id custom:publicationVenue ?publicationVenue . }}\n",
    "          OPTIONAL {{ ?id custom:venueType ?venueType . }}\n",
    "\n",
    "          OPTIONAL {{\n",
    "            ?id schema:publisher ?publisher .\n",
    "            ?publisher schema:name ?publisherName .\n",
    "            BIND(REPLACE(STRAFTER(STR(?publisher), \"schema.org/\"), \"%253A\", \":\") AS ?crossrefID)\n",
    "          }}\n",
    "        }}\n",
    "        GROUP BY ?id ?title\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "\n",
    "    def getPublicationAuthors(self, doi):\n",
    "        query = f\"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        PREFIX custom: <https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/>\n",
    "\n",
    "        SELECT ?author ?givenName ?familyName\n",
    "        WHERE {{\n",
    "          <https://doi.org/{doi}> schema:author ?author .\n",
    "          OPTIONAL {{\n",
    "            ?author schema:givenName ?givenName .\n",
    "            ?author schema:familyName ?familyName .\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "\n",
    "    def getPublicationsByAuthorName(self, name):\n",
    "        # Convert the input name to lowercase\n",
    "        lowercase_name = name.lower()\n",
    "\n",
    "        # Construct the SPARQL query\n",
    "        query = f\"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        PREFIX custom: <https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/>\n",
    "\n",
    "        SELECT ?id ?title \n",
    "               (GROUP_CONCAT(DISTINCT ?publicationVenue; separator=\", \") AS ?publicationVenues) \n",
    "               (GROUP_CONCAT(DISTINCT CONCAT(?givenName, \" \", ?familyName); separator=\", \") AS ?authors)\n",
    "               (GROUP_CONCAT(DISTINCT STR(?citedPublication); separator=\", \") AS ?citedPublications)\n",
    "               (SAMPLE(?publisherName) AS ?publisherNames) (SAMPLE(?crossrefID) AS ?crossrefIDs)\n",
    "               (SAMPLE(?venueType) AS ?venueTypes) (SAMPLE(?issue) AS ?issues) \n",
    "               (SAMPLE(?volume) AS ?volumes) (SAMPLE(?chapter) AS ?chapterNumbers) \n",
    "               (SAMPLE(?event) AS ?events)\n",
    "        WHERE {{\n",
    "          ?id schema:author ?author .\n",
    "          ?author schema:familyName ?familyName .\n",
    "          FILTER(LCASE(STR(?familyName)) = \"{lowercase_name}\")\n",
    "\n",
    "          ?id schema:name ?title .\n",
    "\n",
    "          OPTIONAL {{ ?id custom:publicationVenue ?publicationVenue . }}\n",
    "          OPTIONAL {{ ?id custom:venueType ?venueType . }}\n",
    "\n",
    "          OPTIONAL {{\n",
    "            ?author schema:givenName ?givenName .\n",
    "          }}\n",
    "\n",
    "          OPTIONAL {{\n",
    "            ?id schema:citation ?citedPublication .\n",
    "          }}\n",
    "\n",
    "          OPTIONAL {{\n",
    "            ?id schema:publisher ?publisher .\n",
    "            ?publisher schema:name ?publisherName .\n",
    "            BIND(REPLACE(STRAFTER(STR(?publisher), \"schema.org/\"), \"%253A\", \":\") AS ?crossrefID)\n",
    "          }}\n",
    "\n",
    "          OPTIONAL {{ ?id schema:issueNumber ?issue . }}\n",
    "          OPTIONAL {{ ?id schema:volumeNumber ?volume . }}\n",
    "          OPTIONAL {{ ?id schema:chapterNumber ?chapter . }}\n",
    "          OPTIONAL {{ ?id schema:event ?event . }}\n",
    "        }}\n",
    "        GROUP BY ?id ?title\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "    def getPublicationAuthors(self, doi):\n",
    "        query = f\"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "        PREFIX custom: <https://github.com/AlessandraTrenchi/DS-pablo-ale/storesdb/>\n",
    "\n",
    "        SELECT ?author ?givenName ?familyName\n",
    "        WHERE {{\n",
    "          <https://doi.org/{doi}> schema:author ?author .\n",
    "          OPTIONAL {{\n",
    "            ?author schema:givenName ?givenName .\n",
    "            ?author schema:familyName ?familyName .\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "    def getDistinctPublisherOfPublications(self, dois):\n",
    "        formatted_dois = \" \".join([f\"<https://doi.org/{doi}>\" for doi in dois])\n",
    "        query = f\"\"\"\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "\n",
    "        SELECT DISTINCT ?publisherID ?publisherName\n",
    "        WHERE {{\n",
    "          VALUES ?publication {{ {formatted_dois} }}\n",
    "\n",
    "          ?publication schema:publisher ?publisher .\n",
    "          ?publisher schema:name ?publisherName .\n",
    "          BIND(REPLACE(STRAFTER(STR(?publisher), \"schema.org/\"), \"%253A\", \":\") AS ?publisherID)\n",
    "        }}\n",
    "        \"\"\"\n",
    "        return self.run_query(query)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "06b94978-3278-45fc-be19-d78600addb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publicationVenues</th>\n",
       "      <th>authors</th>\n",
       "      <th>citedPublications</th>\n",
       "      <th>publisherNames</th>\n",
       "      <th>crossrefIDs</th>\n",
       "      <th>venueTypes</th>\n",
       "      <th>issues</th>\n",
       "      <th>volumes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://doi.org/10.1007/s11192-020-03397-6</td>\n",
       "      <td>The Practice Of Self-Citations: A Longitudinal Study</td>\n",
       "      <td>Scientometrics</td>\n",
       "      <td>Silvio Peroni</td>\n",
       "      <td>https://doi.org/10.1038/sdata.2016.18</td>\n",
       "      <td>Springer Science and Business Media LLC</td>\n",
       "      <td>crossref:297</td>\n",
       "      <td>journal</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://doi.org/10.3233/ds-190016</td>\n",
       "      <td>Enabling Text Search On Sparql Endpoints Through Oscar</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Silvio Peroni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IOS Press</td>\n",
       "      <td>crossref:7437</td>\n",
       "      <td>journal</td>\n",
       "      <td>1-2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id  \\\n",
       "0  https://doi.org/10.1007/s11192-020-03397-6   \n",
       "1           https://doi.org/10.3233/ds-190016   \n",
       "\n",
       "                                                    title publicationVenues  \\\n",
       "0    The Practice Of Self-Citations: A Longitudinal Study    Scientometrics   \n",
       "1  Enabling Text Search On Sparql Endpoints Through Oscar      Data Science   \n",
       "\n",
       "         authors                      citedPublications  \\\n",
       "0  Silvio Peroni  https://doi.org/10.1038/sdata.2016.18   \n",
       "1  Silvio Peroni                                    NaN   \n",
       "\n",
       "                            publisherNames    crossrefIDs venueTypes issues  \\\n",
       "0  Springer Science and Business Media LLC   crossref:297    journal      1   \n",
       "1                                IOS Press  crossref:7437    journal    1-2   \n",
       "\n",
       "  volumes  \n",
       "0     123  \n",
       "1       2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\npublishers_results = query_processor.getDistinctPublisherOfPublications([\"10.1007/978-3-030-00461-3_6\", \"10.1007/s10115-017-1100-y\"])\\ndisplay(publishers_results)\\n'"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "# Create an instance of the TriplestoreQueryProcessor class\n",
    "query_processor = TriplestoreQueryProcessor()\n",
    "\n",
    "\n",
    "# Call the getPublicationsPublishedInYear method with the year 2018\n",
    "results = query_processor.getPublicationsPublishedInYear(2018)\n",
    "# Print the results\n",
    "display(results)\n",
    "\n",
    "query_processor = TriplestoreQueryProcessor()\n",
    "orcid_results = query_processor.getPublicationsByAuthorId(\"0000-0002-7383-4634\")\n",
    "display(orcid_results)\n",
    "\n",
    "most_cited_results = query_processor.getMostCitedPublication()\n",
    "display(most_cited_results)\n",
    "\n",
    "most_cited_venue_results = query_processor.getMostCitedVenue()\n",
    "display(most_cited_venue_results)\n",
    "\n",
    "most_cited_publication_in_venue = query_processor.getMostCitedPublicationInVenue()\n",
    "print(most_cited_publication_in_venue)\n",
    "\n",
    "venue_results_issn = query_processor.getPublicationInVenue(\"issn:1061-4036\")\n",
    "display(venue_results_issn)\n",
    "\n",
    "journal_issue_results = query_processor.getJournalArticlesInIssue(\"issn:1061-4036\", \"50\", \"4\")\n",
    "display(journal_issue_results)\n",
    "\n",
    "# Using ISSN for Journal Articles in a Volume\n",
    "articles_in_volume_results = query_processor.getJournalArticlesInVolume(\"issn:1061-4036\", \"50\")\n",
    "display(articles_in_volume_results)\n",
    "\n",
    "# Using ISSN for Journal Articles in a Journal\n",
    "articles_in_journal_results = query_processor.getJournalArticlesInJournal(\"issn:1061-4036\")\n",
    "display(articles_in_journal_results)\n",
    "\n",
    "query_processor = TriplestoreQueryProcessor()\n",
    "proceedings_results = query_processor.getProceedingsByEvent(\"web\")\n",
    "print(proceedings_results)\n",
    "'''\n",
    "\n",
    "\n",
    "query_processor = TriplestoreQueryProcessor()\n",
    "publications_results = query_processor.getPublicationsByAuthorName(\"peroni\")\n",
    "display(publications_results)\n",
    "\n",
    "'''\n",
    "authors_results = query_processor.getPublicationAuthors(\"10.1007/978-3-030-00461-3_6\")\n",
    "display(authors_results)\n",
    "'''\n",
    "'''\n",
    "publishers_results = query_processor.getDistinctPublisherOfPublications([\"10.1007/978-3-030-00461-3_6\", \"10.1007/s10115-017-1100-y\"])\n",
    "display(publishers_results)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "17867d86-ea85-4b97-936c-f0d60c629517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "class RelationalProcessor:\n",
    "    def __init__(self, db_path=None):\n",
    "        self.db_path = db_path\n",
    "        self.connection = self.create_connection() if db_path else None\n",
    "\n",
    "    def get_db_path(self):\n",
    "        return self.db_path\n",
    "\n",
    "    def setDbPath(self, db_path):\n",
    "        self.db_path = db_path\n",
    "        self.connection = self.create_connection()\n",
    "        self.initialize_database()  # Initialize database after setting path\n",
    "\n",
    "    def initialize_database(self):\n",
    "        # Assuming RelationalDataProcessor has the methods `clear_tables` and `create_tables`\n",
    "        processor = RelationalDataProcessor()\n",
    "        processor.db_processor = self  # Set current instance as db_processor\n",
    "        processor.clear_tables()  # Clear tables\n",
    "        processor.create_tables()  # Create tables\n",
    "\n",
    "    def create_connection(self):\n",
    "        if self.db_path:\n",
    "            # Create and return the database connection\n",
    "            return sqlite3.connect(self.db_path)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "class RelationalDataProcessor:\n",
    "    def __init__(self):\n",
    "        self.db_processor = RelationalProcessor()  # Create a new RelationalProcessor instance with no db_path\n",
    "        self.csv_loaded = False\n",
    "        self.json_loaded = False\n",
    "        self.temp_publications = []\n",
    "\n",
    "    # This method will be called directly after setting the database path\n",
    "    def initialize_database(self):\n",
    "        self.clear_tables()  # Clear tables\n",
    "        self.create_tables()  # Create tables\n",
    "    def clear_tables(self):\n",
    "        with self.db_processor.create_connection() as conn:\n",
    "            # Clear all relevant tables before loading new data\n",
    "            tables_to_clear = [\"csv_data\", \"publication_references\", \n",
    "                               \"publications\", \"venues\", \"publishers\", \n",
    "                               \"authors\"]\n",
    "            for table in tables_to_clear:\n",
    "                try:\n",
    "                    conn.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "                    conn.commit()  # Ensure changes are committed\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while dropping {table}: {e}\")\n",
    "\n",
    "    def create_tables(self):\n",
    "    # Connect to the SQLite database\n",
    "        with self.db_processor.create_connection() as conn:\n",
    "            # Create the publications table\n",
    "            conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS publications (\n",
    "                id TEXT PRIMARY KEY,\n",
    "                title TEXT,\n",
    "                publication_year INTEGER,\n",
    "                issue TEXT,\n",
    "                volume TEXT,\n",
    "                chapter_number TEXT,\n",
    "                publisher_crossref TEXT,\n",
    "                publication_venue TEXT,\n",
    "                event TEXT,\n",
    "                type TEXT,\n",
    "                authors TEXT,\n",
    "                venue_id TEXT,\n",
    "                cited_publications TEXT,\n",
    "                publisher_id TEXT\n",
    "            );\n",
    "            \"\"\")\n",
    "    \n",
    "            # Create the authors table\n",
    "            conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS authors (\n",
    "                orcid TEXT,\n",
    "                given_name TEXT,\n",
    "                family_name TEXT,\n",
    "                publication_doi TEXT\n",
    "            );\n",
    "            \"\"\")\n",
    "    \n",
    "            # Modify the venues table to include ISSN and ISBN\n",
    "            conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS venues (\n",
    "                id TEXT,\n",
    "                publication_doi TEXT,\n",
    "                issn TEXT,\n",
    "                isbn TEXT\n",
    "            );\n",
    "            \"\"\")\n",
    "    \n",
    "            # Create the publishers table\n",
    "            conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS publishers (\n",
    "                id TEXT,\n",
    "                name TEXT,\n",
    "                crossref TEXT\n",
    "            );\n",
    "            \"\"\")\n",
    "    \n",
    "            # Rename references table to avoid using a reserved keyword\n",
    "            conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS publication_references (\n",
    "                publication_doi TEXT,\n",
    "                referenced_doi TEXT\n",
    "            );\n",
    "            \"\"\")\n",
    "\n",
    "            # Create the csv_data table\n",
    "            conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS csv_data (\n",
    "                id TEXT PRIMARY KEY,\n",
    "                title TEXT,\n",
    "                publication_year INTEGER,\n",
    "                issue TEXT,\n",
    "                volume TEXT,\n",
    "                chapter_number TEXT,\n",
    "                publisher_crossref TEXT,\n",
    "                publication_venue TEXT,\n",
    "                event TEXT,\n",
    "                type TEXT\n",
    "            );\n",
    "            \"\"\")\n",
    "    \n",
    "            conn.commit()\n",
    "\n",
    "\n",
    "    def uploadData(self, path: str):\n",
    "        # Check the file extension and call the appropriate loading function\n",
    "        if path.lower().endswith('.csv'):\n",
    "            success = self.load_csv(path)\n",
    "        elif path.lower().endswith('.json'):\n",
    "            success = self.load_json(path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type. Please provide a .csv or .json file.\")\n",
    "\n",
    "        # If both CSV and JSON data have been loaded, upload data to the relational database\n",
    "        if self.csv_loaded and self.json_loaded:\n",
    "            self.upload_data_to_db()\n",
    "        return success\n",
    "\n",
    "    def load_csv(self, csv_path: str):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        with self.db_processor.create_connection() as conn:\n",
    "            # Clear existing data in the tables\n",
    "            conn.execute(\"DELETE FROM csv_data\")\n",
    "            conn.execute(\"DELETE FROM publications\")  # Clear publications table\n",
    "    \n",
    "            for index, row in df.iterrows():\n",
    "                # Insert into csv_data table\n",
    "                csv_sql = \"\"\"\n",
    "                INSERT INTO csv_data (id, title, publication_year, issue, volume, chapter_number, publisher_crossref, publication_venue, event, type)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                \"\"\"\n",
    "                csv_data = (\n",
    "                    row['id'],\n",
    "                    row['title'],\n",
    "                    row['publication_year'],\n",
    "                    row.get('issue'),\n",
    "                    row.get('volume'),\n",
    "                    row.get('chapter'),\n",
    "                    row.get('publisher'),\n",
    "                    row.get('publication_venue'),\n",
    "                    row.get('event'),\n",
    "                    row['type']\n",
    "                )\n",
    "                conn.execute(csv_sql, csv_data)\n",
    "    \n",
    "                # Also, insert into publications table\n",
    "                # Adjust the columns and data as per your publications table schema\n",
    "                pub_sql = \"\"\"\n",
    "                INSERT INTO publications (id, title, publication_year, issue, volume, chapter_number, publisher_crossref, publication_venue, event, type)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                \"\"\"\n",
    "                pub_data = (\n",
    "                    row['id'],\n",
    "                    row['title'],\n",
    "                    row['publication_year'],\n",
    "                    row.get('issue'),\n",
    "                    row.get('volume'),\n",
    "                    row.get('chapter'),\n",
    "                    row.get('publisher'),\n",
    "                    row.get('publication_venue'),\n",
    "                    row.get('event'),\n",
    "                    row['type']\n",
    "                )\n",
    "                conn.execute(pub_sql, pub_data)\n",
    "    \n",
    "        self.csv_loaded = True\n",
    "        return True\n",
    "\n",
    "    \n",
    "    def load_json(self, json_path: str):\n",
    "        with open(json_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        \n",
    "        with self.db_processor.create_connection() as conn:\n",
    "            # Process authors\n",
    "            for doi, authors in json_data['authors'].items():\n",
    "                for author in authors:\n",
    "                    sql = \"INSERT INTO authors (orcid, given_name, family_name, publication_doi) VALUES (?, ?, ?, ?)\"\n",
    "                    data = (author['orcid'], author['given'], author['family'], doi)\n",
    "                    conn.execute(sql, data)\n",
    "    \n",
    "            # Process venues\n",
    "            for doi, venue_ids in json_data['venues_id'].items():\n",
    "                for venue_id in venue_ids:\n",
    "                    # Check if it's ISSN or ISBN and insert accordingly\n",
    "                    issn = venue_id if venue_id.startswith('issn:') else None\n",
    "                    isbn = venue_id if venue_id.startswith('isbn:') else None\n",
    "    \n",
    "                    sql = \"INSERT INTO venues (id, publication_doi, issn, isbn) VALUES (?, ?, ?, ?)\"\n",
    "                    data = (None, doi, issn, isbn)  # 'id' can be None or some identifier if needed\n",
    "                    conn.execute(sql, data)\n",
    "    \n",
    "            # Process publishers\n",
    "            for crossref, publisher in json_data['publishers'].items():\n",
    "                sql = \"INSERT INTO publishers (id, name, crossref) VALUES (?, ?, ?)\"\n",
    "                data = (publisher['id'], publisher['name'], crossref)\n",
    "                conn.execute(sql, data)\n",
    "    \n",
    "            # Process publication references\n",
    "            for doi, references in json_data['references'].items():\n",
    "                for reference in references:\n",
    "                    sql = \"INSERT INTO publication_references (publication_doi, referenced_doi) VALUES (?, ?)\"\n",
    "                    data = (doi, reference)\n",
    "                    conn.execute(sql, data)\n",
    "    \n",
    "        self.json_loaded = True\n",
    "        return True\n",
    "\n",
    "    def enrich_publications(self):\n",
    "        with self.db_processor.create_connection() as conn:\n",
    "            # Connect authors based on DOI\n",
    "            sql = \"\"\"\n",
    "            UPDATE publications\n",
    "            SET authors = (\n",
    "                SELECT GROUP_CONCAT(given_name || ' ' || family_name) \n",
    "                FROM authors \n",
    "                WHERE publication_doi = publications.id\n",
    "            )\n",
    "            \"\"\"\n",
    "            conn.execute(sql)\n",
    "            \n",
    "            # Connect venues based on DOI\n",
    "            sql = \"\"\"\n",
    "            UPDATE publications\n",
    "            SET venue_id = (SELECT id FROM venues WHERE publication_doi = publications.id LIMIT 1)\n",
    "            \"\"\"\n",
    "            conn.execute(sql)\n",
    "            \n",
    "            # Connect references based on DOI\n",
    "            sql = \"\"\"\n",
    "            UPDATE publications\n",
    "            SET cited_publications = (\n",
    "                SELECT GROUP_CONCAT(referenced_doi) \n",
    "                FROM publication_references \n",
    "                WHERE publication_doi = publications.id\n",
    "            )\n",
    "            \"\"\"\n",
    "            conn.execute(sql)\n",
    "            \n",
    "            # Update titles where necessary\n",
    "            sql = \"\"\"\n",
    "            UPDATE publications\n",
    "            SET title = (\n",
    "                SELECT title FROM csv_data WHERE id = publications.id AND title IS NOT NULL\n",
    "            )\n",
    "            WHERE title = 'Title not provided'\n",
    "            \"\"\"\n",
    "            conn.execute(sql)\n",
    "            \n",
    "            # Connect publisher based on Crossref value from CSV\n",
    "            sql = \"\"\"\n",
    "            UPDATE publications\n",
    "            SET publisher_id = (SELECT id FROM publishers WHERE crossref = publications.publisher_crossref)\n",
    "            \"\"\"\n",
    "            conn.execute(sql)\n",
    "            \n",
    "            # Update event for ProceedingsPaper\n",
    "            sql = \"\"\"\n",
    "            UPDATE publications\n",
    "            SET event = (\n",
    "                SELECT event FROM csv_data WHERE id = publications.id AND type = 'proceedings-paper' AND event IS NOT NULL\n",
    "            )\n",
    "            WHERE type = 'proceedings-paper' AND event IS NULL OR event = ''\n",
    "            \"\"\"\n",
    "            conn.execute(sql)\n",
    "            \n",
    "            # Update titles where necessary\n",
    "            sql = \"\"\"\n",
    "            UPDATE publications\n",
    "            SET title = (\n",
    "                SELECT title FROM csv_data WHERE id = publications.id AND title IS NOT NULL\n",
    "            )\n",
    "            WHERE title = 'Title not provided'\n",
    "            \"\"\"\n",
    "            conn.execute(sql)\n",
    "\n",
    "    def upload_data_to_db(self):\n",
    "        with self.db_processor.create_connection() as conn:\n",
    "            for publication in self.temp_publications:\n",
    "                # Determine the type of publication and prepare the SQL statement and data accordingly\n",
    "                if isinstance(publication, JournalArticle):\n",
    "                    table = 'journal_articles'\n",
    "                    columns = ['id', 'title', 'publication_year', 'issue', 'volume', 'publisher_id']  # example columns\n",
    "                elif isinstance(publication, BookChapter):\n",
    "                    table = 'book_chapters'\n",
    "                    columns = ['id', 'title', 'publication_year', 'chapter_number', 'publisher_id']  # example columns\n",
    "                elif isinstance(publication, ProceedingsPaper):\n",
    "                    table = 'proceedings_papers'\n",
    "                    columns = ['id', 'title', 'publication_year', 'event', 'publisher_id']  # example columns\n",
    "                else:\n",
    "                    table = 'publications'\n",
    "                    columns = ['id', 'title', 'publication_year', 'publisher_id']  # example columns\n",
    "                \n",
    "                # Prepare the SQL command\n",
    "                sql = f\"INSERT INTO {table} ({', '.join(columns)}) VALUES ({', '.join(['?'] * len(columns))})\"\n",
    "                \n",
    "                # Prepare data tuple for the SQL query\n",
    "                data = [getattr(publication, column, None) for column in columns]\n",
    "                \n",
    "                # Execute the SQL command\n",
    "                conn.execute(sql, data)\n",
    "    \n",
    "            # Committing at the end of all inserts for efficiency\n",
    "            conn.commit()\n",
    "    \n",
    "    def prepare_data_tuple(self, publication):\n",
    "        # Assuming publication object has properties named after the database columns\n",
    "        if isinstance(publication, JournalArticle):\n",
    "            return (publication.id, publication.title, publication.publicationYear, publication.issue, publication.volume, publication.publisher)\n",
    "        elif isinstance(publication, BookChapter):\n",
    "            return (publication.id, publication.title, publication.publicationYear, publication.chapterNumber, publication.publisher)\n",
    "        elif isinstance(publication, ProceedingsPaper):\n",
    "            return (publication.id, publication.title, publication.publicationYear, publication.event, publication.publisher)\n",
    "        else:  # Generic Publication or other types\n",
    "            return (publication.id, publication.title, publication.publicationYear, publication.publisher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "ccd89961-595f-4809-b7c8-936e6226839e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publicationVenues</th>\n",
       "      <th>authors</th>\n",
       "      <th>citedPublications</th>\n",
       "      <th>publisherNames</th>\n",
       "      <th>crossrefIDs</th>\n",
       "      <th>venueTypes</th>\n",
       "      <th>issues</th>\n",
       "      <th>volumes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://doi.org/10.1007/s11192-020-03397-6</td>\n",
       "      <td>The Practice Of Self-Citations: A Longitudinal Study</td>\n",
       "      <td>Scientometrics</td>\n",
       "      <td>Silvio Peroni</td>\n",
       "      <td>https://doi.org/10.1038/sdata.2016.18</td>\n",
       "      <td>Springer Science and Business Media LLC</td>\n",
       "      <td>crossref:297</td>\n",
       "      <td>journal</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://doi.org/10.3233/ds-190016</td>\n",
       "      <td>Enabling Text Search On Sparql Endpoints Through Oscar</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Silvio Peroni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IOS Press</td>\n",
       "      <td>crossref:7437</td>\n",
       "      <td>journal</td>\n",
       "      <td>1-2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id  \\\n",
       "0  https://doi.org/10.1007/s11192-020-03397-6   \n",
       "1           https://doi.org/10.3233/ds-190016   \n",
       "\n",
       "                                                    title publicationVenues  \\\n",
       "0    The Practice Of Self-Citations: A Longitudinal Study    Scientometrics   \n",
       "1  Enabling Text Search On Sparql Endpoints Through Oscar      Data Science   \n",
       "\n",
       "         authors                      citedPublications  \\\n",
       "0  Silvio Peroni  https://doi.org/10.1038/sdata.2016.18   \n",
       "1  Silvio Peroni                                    NaN   \n",
       "\n",
       "                            publisherNames    crossrefIDs venueTypes issues  \\\n",
       "0  Springer Science and Business Media LLC   crossref:297    journal      1   \n",
       "1                                IOS Press  crossref:7437    journal    1-2   \n",
       "\n",
       "  volumes  \n",
       "0     123  \n",
       "1       2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RelationalQueryProcessor(RelationalProcessor):\n",
    "    def __init__(self, db_path=None):\n",
    "        super().__init__(db_path=db_path)\n",
    "\n",
    "    def setDbProcessor(self, db_processor):\n",
    "        self.db_processor = db_processor\n",
    "        \n",
    "    def getPublicationsPublishedInYear(self, year):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "            \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            p.id,\n",
    "            p.title,\n",
    "            p.publication_venue AS publicationVenues,\n",
    "            GROUP_CONCAT(a.given_name || ' ' || a.family_name, ', ') AS authors,\n",
    "            citing.citing_publications AS citedPublications,\n",
    "            pub.name AS publisherNames,\n",
    "            pub.crossref AS crossrefIDs,\n",
    "            p.type AS venueTypes,\n",
    "            p.issue AS issues,\n",
    "            p.volume AS volumes,\n",
    "            p.chapter_number AS chapterNumbers,\n",
    "            p.event AS events\n",
    "        FROM \n",
    "            publications p\n",
    "        LEFT JOIN \n",
    "            venues v ON p.id = v.publication_doi\n",
    "        LEFT JOIN \n",
    "            authors a ON p.id = a.publication_doi\n",
    "        LEFT JOIN \n",
    "            (SELECT \n",
    "                 pr.referenced_doi, \n",
    "                 GROUP_CONCAT(pr.publication_doi, ', ') AS citing_publications\n",
    "             FROM \n",
    "                 publication_references pr\n",
    "             GROUP BY \n",
    "                 pr.referenced_doi) citing ON p.id = citing.referenced_doi\n",
    "        LEFT JOIN \n",
    "            publishers pub ON p.publisher_crossref = pub.id\n",
    "        WHERE \n",
    "            p.publication_year = ?\n",
    "        GROUP BY\n",
    "            p.id, p.title, p.publication_venue, pub.name, pub.crossref, p.type, p.issue, p.volume, p.chapter_number, p.event;\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(query, conn, params=(year,))\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    def getPublicationsByAuthorId(self, author_id):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            p.id,\n",
    "            p.title,\n",
    "            p.publication_venue AS publicationVenues,\n",
    "            GROUP_CONCAT(a.given_name || ' ' || a.family_name, ', ') AS authors,\n",
    "            citing.citing_publications AS citedPublications,\n",
    "            pub.name AS publisherNames,\n",
    "            pub.crossref AS crossrefIDs,\n",
    "            p.type AS venueTypes,\n",
    "            p.issue AS issues,\n",
    "            p.volume AS volumes,\n",
    "            p.chapter_number AS chapterNumbers,\n",
    "            p.event AS events\n",
    "        FROM \n",
    "            publications p\n",
    "        LEFT JOIN \n",
    "            authors a ON p.id = a.publication_doi\n",
    "        LEFT JOIN \n",
    "            (SELECT \n",
    "                 pr.referenced_doi, \n",
    "                 GROUP_CONCAT(pr.publication_doi, ', ') AS citing_publications\n",
    "             FROM \n",
    "                 publication_references pr\n",
    "             GROUP BY \n",
    "                 pr.referenced_doi) citing ON p.id = citing.referenced_doi\n",
    "        LEFT JOIN \n",
    "            publishers pub ON p.publisher_crossref = pub.id\n",
    "        WHERE \n",
    "            a.orcid = ?\n",
    "        GROUP BY\n",
    "            p.id, p.title, p.publication_venue, pub.name, pub.crossref, p.type, p.issue, p.volume, p.chapter_number, p.event;\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(query, conn, params=(author_id,))\n",
    "        conn.close()\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def getMostCitedPublication(self):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            p.id,\n",
    "            p.title,\n",
    "            p.publication_venue AS publicationVenues,\n",
    "            (SELECT GROUP_CONCAT(a2.given_name || ' ' || a2.family_name, ', ')\n",
    "             FROM authors a2 \n",
    "             WHERE a2.publication_doi = p.id) AS authors,\n",
    "            citationCount,\n",
    "            pub.name AS publisherNames,\n",
    "            pub.crossref AS crossrefIDs,\n",
    "            p.type AS venueTypes,\n",
    "            p.issue AS issues,\n",
    "            p.volume AS volumes,\n",
    "            p.chapter_number AS chapterNumbers,\n",
    "            p.event AS events\n",
    "        FROM \n",
    "            (SELECT pr.referenced_doi, COUNT(*) AS citationCount\n",
    "             FROM publication_references pr\n",
    "             GROUP BY pr.referenced_doi\n",
    "             ORDER BY COUNT(*) DESC\n",
    "             LIMIT 1) AS most_cited\n",
    "        JOIN \n",
    "            publications p ON most_cited.referenced_doi = p.id\n",
    "        LEFT JOIN \n",
    "            publishers pub ON p.publisher_crossref = pub.id;\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    def getMostCitedVenue(self):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            p.publication_venue AS venue,\n",
    "            p.type AS venueTypes,\n",
    "            pub.name AS publisherNames,\n",
    "            pub.crossref AS crossrefIDs,\n",
    "            SUM(citationCount) AS totalCitations\n",
    "        FROM \n",
    "            (SELECT \n",
    "                 pr.referenced_doi, \n",
    "                 COUNT(*) AS citationCount\n",
    "             FROM \n",
    "                 publication_references pr\n",
    "             GROUP BY \n",
    "                 pr.referenced_doi) AS citation_counts\n",
    "        JOIN \n",
    "            publications p ON citation_counts.referenced_doi = p.id\n",
    "        JOIN \n",
    "            publishers pub ON p.publisher_crossref = pub.id\n",
    "        GROUP BY \n",
    "            p.publication_venue, p.type, pub.name, pub.crossref\n",
    "        ORDER BY \n",
    "            totalCitations DESC\n",
    "        LIMIT 1;\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    def getVenuesByPublisherId(self, publisher_id):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            p.id,\n",
    "            p.title,\n",
    "            p.publication_venue AS publicationVenues,\n",
    "            (SELECT GROUP_CONCAT(a2.given_name || ' ' || a2.family_name, ', ')\n",
    "             FROM authors a2 \n",
    "             WHERE a2.publication_doi = p.id) AS authors,\n",
    "            pr_agg.citing_publications AS citedPublications,\n",
    "            pub.name AS publisherNames,\n",
    "            pub.crossref AS crossrefIDs,\n",
    "            p.type AS venueTypes,\n",
    "            p.issue AS issues,\n",
    "            p.volume AS volumes,\n",
    "            p.chapter_number AS chapterNumbers,\n",
    "            p.event AS events\n",
    "        FROM \n",
    "            publications p\n",
    "        LEFT JOIN \n",
    "            venues v ON p.id = v.publication_doi\n",
    "        LEFT JOIN \n",
    "            (SELECT \n",
    "                 pr.referenced_doi, \n",
    "                 GROUP_CONCAT(pr.publication_doi, ', ') AS citing_publications\n",
    "             FROM \n",
    "                 publication_references pr\n",
    "             GROUP BY \n",
    "                 pr.referenced_doi) pr_agg ON p.id = pr_agg.referenced_doi\n",
    "        LEFT JOIN \n",
    "            publishers pub ON p.publisher_crossref = pub.id\n",
    "        WHERE \n",
    "            pub.id = ?;\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(query, conn, params=(publisher_id,))\n",
    "        conn.close()\n",
    "        return df\n",
    "\n",
    "    def getJournalArticlesInVolume(self, issn, volume):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            p.id,\n",
    "            p.title,\n",
    "            p.publication_year AS publicationYears,\n",
    "            p.issue AS issues,\n",
    "            p.volume AS volumes,\n",
    "            pub.name AS publisherNames,\n",
    "            pub.crossref AS crossrefIDs,\n",
    "            p.publication_venue AS publicationVenues,\n",
    "            p.type AS venueTypes\n",
    "        FROM \n",
    "            publications p\n",
    "        LEFT JOIN \n",
    "            publishers pub ON p.publisher_crossref = pub.id\n",
    "        LEFT JOIN \n",
    "            venues v ON p.id = v.publication_doi\n",
    "        WHERE \n",
    "            v.issn = ? AND\n",
    "            p.volume = ? AND\n",
    "            p.type = 'journal-article';\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.read_sql_query(query, conn, params=(issn, volume))\n",
    "        conn.close()\n",
    "        return df    \n",
    "    \n",
    "    def getJournalArticlesInIssue(self, issn, volume, issue):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "    \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            p.id,\n",
    "            p.title,\n",
    "            p.publication_year AS publicationYears,\n",
    "            p.issue AS issues,\n",
    "            p.volume AS volumes,\n",
    "            pub.name AS publisherNames,\n",
    "            pub.crossref AS crossrefIDs,\n",
    "            p.publication_venue AS publicationVenues,\n",
    "            p.type AS venueTypes\n",
    "        FROM \n",
    "            publications p\n",
    "        LEFT JOIN \n",
    "            publishers pub ON p.publisher_crossref = pub.id\n",
    "        LEFT JOIN \n",
    "            venues v ON p.id = v.publication_doi\n",
    "        WHERE \n",
    "            v.issn = ? AND\n",
    "            p.type = 'journal-article' AND\n",
    "            p.issue = ? AND\n",
    "            p.volume = ?;\n",
    "        \"\"\"\n",
    "    \n",
    "        df = pd.read_sql_query(query, conn, params=(issn, volume, issue))\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    def getPublicationInVenue(self, venue_identifier):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "    \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            p.id,\n",
    "            p.title,\n",
    "            p.publication_venue AS publicationVenues,\n",
    "            (SELECT GROUP_CONCAT(a2.given_name || ' ' || a2.family_name, ', ')\n",
    "             FROM authors a2 \n",
    "             WHERE a2.publication_doi = p.id) AS authors,\n",
    "            pr_agg.citing_publications AS citedPublications,\n",
    "            pub.name AS publisherNames,\n",
    "            pub.crossref AS crossrefIDs,\n",
    "            p.type AS venueTypes,\n",
    "            p.issue AS issues,\n",
    "            p.volume AS volumes,\n",
    "            p.chapter_number AS chapterNumbers,\n",
    "            p.event AS events\n",
    "        FROM \n",
    "            publications p\n",
    "        LEFT JOIN \n",
    "            venues v ON p.id = v.publication_doi\n",
    "        LEFT JOIN \n",
    "            (SELECT \n",
    "                 pr.referenced_doi, \n",
    "                 GROUP_CONCAT(pr.publication_doi, ', ') AS citing_publications\n",
    "             FROM \n",
    "                 publication_references pr\n",
    "             GROUP BY \n",
    "                 pr.referenced_doi) pr_agg ON p.id = pr_agg.referenced_doi\n",
    "        LEFT JOIN \n",
    "            publishers pub ON p.publisher_crossref = pub.id\n",
    "        WHERE \n",
    "            v.issn = ? OR v.isbn = ?\n",
    "        \"\"\"\n",
    "    \n",
    "        df = pd.read_sql_query(query, conn, params=(venue_identifier, venue_identifier))\n",
    "        conn.close()\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def getJournalArticlesInJournal(self, issn):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "    \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            p.id,\n",
    "            p.title,\n",
    "            p.publication_year AS publicationYears,\n",
    "            p.issue AS issues,\n",
    "            p.volume AS volumes,\n",
    "            pub.name AS publisherNames,\n",
    "            pub.crossref AS crossrefIDs,\n",
    "            p.publication_venue AS publicationVenues,\n",
    "            p.type AS venueTypes\n",
    "        FROM \n",
    "            publications p\n",
    "        LEFT JOIN \n",
    "            publishers pub ON p.publisher_crossref = pub.id\n",
    "        LEFT JOIN \n",
    "            venues v ON p.id = v.publication_doi\n",
    "        WHERE \n",
    "            v.issn = ? AND\n",
    "            p.type = 'journal-article';\n",
    "        \"\"\"\n",
    "    \n",
    "        df = pd.read_sql_query(query, conn, params=(issn,))\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    def getProceedingsByEvent(self, event_name):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "    \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            p.id,\n",
    "            p.title,\n",
    "            p.publication_year AS publicationYears,\n",
    "            p.issue AS issues,\n",
    "            p.volume AS volumes,\n",
    "            pub.name AS publisherNames,\n",
    "            pub.crossref AS crossrefIDs,\n",
    "            p.publication_venue AS publicationVenues,\n",
    "            p.type AS venueTypes\n",
    "        FROM \n",
    "            publications p\n",
    "        LEFT JOIN \n",
    "            publishers pub ON p.publisher_crossref = pub.id\n",
    "        WHERE \n",
    "            p.type = 'proceedings' AND\n",
    "            LOWER(p.event) LIKE '%' || LOWER(?) || '%';\n",
    "        \"\"\"\n",
    "    \n",
    "        df = pd.read_sql_query(query, conn, params=('%' + event_name.lower() + '%',))\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    def getPublicationAuthors(self, publication_doi):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "    \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            orcid,\n",
    "            family_name AS familyName,\n",
    "            given_name AS givenName\n",
    "        FROM \n",
    "            authors\n",
    "        WHERE \n",
    "            publication_doi = ?;\n",
    "        \"\"\"\n",
    "    \n",
    "        df = pd.read_sql_query(query, conn, params=(publication_doi,))\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    def getPublicationsByAuthorName(self, author_name):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "    \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            p.id,\n",
    "            p.title,\n",
    "            p.publication_venue AS publicationVenues,\n",
    "            (SELECT GROUP_CONCAT(a2.given_name || ' ' || a2.family_name, ', ')\n",
    "             FROM authors a2 \n",
    "             WHERE a2.publication_doi = p.id) AS authors,\n",
    "            (SELECT GROUP_CONCAT(pr2.publication_doi, ', ')\n",
    "             FROM publication_references pr2\n",
    "             WHERE pr2.referenced_doi = p.id) AS citedPublications,\n",
    "            pub.name AS publisherNames,\n",
    "            pub.crossref AS crossrefIDs,\n",
    "            p.type AS venueTypes,\n",
    "            p.issue AS issues,\n",
    "            p.volume AS volumes,\n",
    "            p.chapter_number AS chapterNumbers,\n",
    "            p.event AS events\n",
    "        FROM \n",
    "            publications p\n",
    "        LEFT JOIN \n",
    "            authors a ON p.id = a.publication_doi\n",
    "        LEFT JOIN \n",
    "            publishers pub ON p.publisher_crossref = pub.id\n",
    "        WHERE \n",
    "            LOWER(a.given_name || ' ' || a.family_name) LIKE '%' || LOWER(?) || '%'\n",
    "        GROUP BY\n",
    "            p.id, p.title, p.publication_venue, pub.name, pub.crossref, p.type, p.issue, p.volume, p.chapter_number, p.event;\n",
    "        \"\"\"\n",
    "    \n",
    "        name_pattern = f'%{author_name.lower()}%'\n",
    "        df = pd.read_sql_query(query, conn, params=(name_pattern,))\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def getDistinctPublisherOfPublications(self, publication_dois):\n",
    "        # Use the connection from the associated RelationalDataProcessor\n",
    "        if self.db_processor and self.db_processor.connection:\n",
    "            conn = self.db_processor.connection\n",
    "        else:\n",
    "            print(\"Database connection not established.\")\n",
    "            return None\n",
    "    \n",
    "        placeholders = ', '.join(['?'] * len(publication_dois))\n",
    "        query = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            pub.id AS publisherID,\n",
    "            pub.name AS publisherName\n",
    "        FROM \n",
    "            publications p\n",
    "        JOIN \n",
    "            publishers pub ON p.publisher_crossref = pub.id\n",
    "        WHERE \n",
    "            p.id IN ({placeholders});\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "        df = pd.read_sql_query(query, conn, params=publication_dois)\n",
    "        conn.close()\n",
    "        return df\n",
    "\n",
    "'''\n",
    "# Set display options to show all columns and rows without truncation\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Initialization of the database processor and query processor\n",
    "db_path = 'aath_to_your_database.db'\n",
    "db_processor = RelationalProcessor(db_path)  # Create an instance of RelationalProcessor\n",
    "query_processor = RelationalQueryProcessor()\n",
    "query_processor.setDbProcessor(db_processor)  \n",
    "\n",
    "\n",
    "# Example usage with standardized print calls\n",
    "display(query_processor.getPublicationsPublishedInYear(2020))\n",
    "\n",
    "display(query_processor.getPublicationsByAuthorId(\"0000-0001-9857-1511\"))\n",
    "\n",
    "display(query_processor.getMostCitedPublication())\n",
    "\n",
    "display(query_processor.getMostCitedVenue())\n",
    "\n",
    "display(query_processor.getVenuesByPublisherId(\"crossref:78\"))\n",
    "\n",
    "display(query_processor.getJournalArticlesInVolume(\"issn:2641-3337\", \"1\"))\n",
    "\n",
    "display(query_processor.getJournalArticlesInIssue('issn:2641-3337', '1', '1'))\n",
    "\n",
    "display(query_processor.getJournalArticlesInVolume('issn:2164-5515', '17'))\n",
    "\n",
    "display(query_processor.getJournalArticlesInJournal('issn:2164-5515'))\n",
    "\n",
    "display(query_processor.getProceedingsByEvent('web'))\n",
    "\n",
    "display(query_processor.getPublicationAuthors('doi:10.1080/21645515.2021.1910000'))\n",
    "\n",
    "\n",
    "\n",
    "display(query_processor.getDistinctPublisherOfPublications([\"doi:10.1080/21645515.2021.1910000\", \"doi:10.3390/ijfs9030035\"]))\n",
    "\n",
    "'''\n",
    "display(query_processor.getPublicationsByAuthorName('Peroni'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "38ccaf52-9197-45a9-977a-477cc20ed69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryProcessor():\n",
    "        pass\n",
    "\n",
    "class GenericQueryProcessor(QueryProcessor):\n",
    "    def __init__(self):\n",
    "        self.query_processors = []\n",
    "\n",
    "    def clean_query_processors(self):\n",
    "        self.query_processors.clear()\n",
    "        return True\n",
    "\n",
    "    def addQueryProcessor(self, query_processor):\n",
    "        self.query_processors.append(query_processor)\n",
    "    \n",
    "    def getPublicationsPublishedInYear(self, year):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            result = processor.getPublicationsPublishedInYear(year)\n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "    \n",
    "        # Combine all results into a single DataFrame\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if no results\n",
    "\n",
    "    def getPublicationsByAuthorId(self, author_id):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            result = processor.getPublicationsByAuthorId(author_id)\n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame() \n",
    "\n",
    "    def getMostCitedPublication(self):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            result = processor.getMostCitedPublication()\n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame() \n",
    "\n",
    "    def getMostCitedVenue(self):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            result = processor.getMostCitedVenue()\n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame()  \n",
    "            \n",
    "    def getVenuesByPublisherId(self, publisher_id):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            result = processor.getVenuesByPublisherId(publisher_id)\n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def getPublicationInVenue(self, venue_id):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            result = processor.getPublicationInVenue(venue_id)\n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame() \n",
    "\n",
    "    def getJournalArticlesInIssue(self, journal_id, volume, issue):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            # Directly pass the parameters to the processor's method\n",
    "            result = processor.getJournalArticlesInIssue(journal_id, volume, issue)\n",
    "            \n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def getJournalArticlesInVolume(self, issn, volume):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            result = processor.getJournalArticlesInVolume(issn, volume)\n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def getJournalArticlesInJournal(self, issn):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            result = processor.getJournalArticlesInJournal(issn)\n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def getProceedingsByEvent(self, event_name):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            result = processor.getProceedingsByEvent(event_name)\n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def getPublicationAuthors(self, publication_id):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            result = processor.getPublicationAuthors(publication_id)\n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame() \n",
    "\n",
    "    def getPublicationsByAuthorName(self, author_name):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            result = processor.getPublicationsByAuthorName(author_name)\n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def getDistinctPublisherOfPublications(self, publication_ids):\n",
    "        merged_results = []\n",
    "        for processor in self.query_processors:\n",
    "            result = processor.getDistinctPublisherOfPublications(publication_ids)\n",
    "            if result is not None and not result.empty:\n",
    "                merged_results.append(result)\n",
    "            else:\n",
    "                print(f\"No data or empty result from {type(processor).__name__}\")\n",
    "\n",
    "        if merged_results:\n",
    "            combined_results = pd.concat(merged_results, ignore_index=True)\n",
    "            return combined_results\n",
    "        else:\n",
    "            return pd.DataFrame() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "26ec8114-d847-4863-a5bc-a365a8f5f163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data or empty result from TriplestoreQueryProcessor\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisherID</th>\n",
       "      <th>publisherName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crossref:301</td>\n",
       "      <td>Informa UK Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crossref:1968</td>\n",
       "      <td>MDPI AG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     publisherID       publisherName\n",
       "0   crossref:301  Informa UK Limited\n",
       "1  crossref:1968             MDPI AG"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Once all the classes are imported, first create the relational\n",
    "# database using the related source data\n",
    "rel_path = \"aath_to_your_database.db\"\n",
    "rel_dp = RelationalDataProcessor()\n",
    "rel_dp.db_processor.setDbPath(rel_path)  \n",
    "rel_dp.uploadData(\"data/relational_publications.csv\")\n",
    "rel_dp.uploadData(\"data/relational_other_data.json\")\n",
    "\n",
    "# Then, create the RDF triplestore (remember first to run the\n",
    "# Blazegraph instance) using the related source data\n",
    "grp_endpoint = \"http://127.0.0.1:9999/blazegraph/sparql\"\n",
    "grp_dp = TriplestoreDataProcessor()\n",
    "grp_dp.setEndpointUrl(grp_endpoint)\n",
    "grp_dp.uploadData(\"/Users/juanpablocasadobissone/Downloads/graph_publications.csv\")\n",
    "grp_dp.uploadData(\"/Users/juanpablocasadobissone/Downloads/graph_other_data.json\")\n",
    "\n",
    "# In the next passage, create the query processors for both\n",
    "# the databases, using the related classes\n",
    "rel_qp = RelationalQueryProcessor()\n",
    "rel_qp.setDbProcessor(rel_dp.db_processor)  \n",
    "\n",
    "grp_qp = TriplestoreQueryProcessor()\n",
    "grp_qp.setEndpointUrl(grp_endpoint)\n",
    "\n",
    "# Create a generic query processor and add the specific processors\n",
    "generic = GenericQueryProcessor()\n",
    "generic.addQueryProcessor(rel_qp)\n",
    "generic.addQueryProcessor(grp_qp)\n",
    "\n",
    "# Set display options to show all columns and rows without truncation\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "'''\n",
    "result = generic.getPublicationsPublishedInYear(2018)\n",
    "display(result)\n",
    "'''\n",
    "'''\n",
    "result_q2 = generic.getPublicationsByAuthorId(\"0000-0001-9857-1511\")\n",
    "display(result_q2)\n",
    "'''\n",
    "'''\n",
    "result_q3 = generic.getMostCitedPublication()\n",
    "display(result_q3)\n",
    "'''\n",
    "'''\n",
    "result_q4 = generic.getMostCitedVenue()\n",
    "display(result_q4)\n",
    "'''\n",
    "'''\n",
    "result_q4 = generic.getVenuesByPublisherId(\"crossref:78\")\n",
    "display(result_q4)\n",
    "'''\n",
    "'''\n",
    "result_q5 = generic.getPublicationInVenue(\"issn:0944-1344\")\n",
    "display(result_q5)\n",
    "'''\n",
    "'''\n",
    "result_q6 = generic.getJournalArticlesInIssue('issn:1061-4036', '50', '4')\n",
    "display(result_q6)\n",
    "'''\n",
    "'''\n",
    "result_journal_volume = generic.getJournalArticlesInVolume(\"issn:1061-4036\", \"50\")\n",
    "display(result_journal_volume)\n",
    "'''\n",
    "'''\n",
    "result_journal = generic.getJournalArticlesInJournal(\"issn:1061-4036\")\n",
    "display(result_journal)\n",
    "'''\n",
    "'''\n",
    "result_publication_authors = generic.getProceedingsByEvent(\"web\")\n",
    "display(result_proceedings)\n",
    "'''\n",
    "'''\n",
    "result_authors = generic.getPublicationAuthors(\"doi:10.1080/21645515.2021.1910000\")\n",
    "display(result_authors)\n",
    "'''\n",
    "'''\n",
    "result_publications_by_author = generic.getPublicationsByAuthorName(\"peroni\")\n",
    "display(result_publications_by_author)\n",
    "'''\n",
    "'''\n",
    "result_publishers = generic.getDistinctPublisherOfPublications([\"doi:10.1080/21645515.2021.1910000\", \"doi:10.3390/ijfs9030035\"])\n",
    "display(result_publishers)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b59d47-2310-43a3-8dd8-445c83f49836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5cae1b-c7e1-4b88-b75d-d95bbe251ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fa9371-36eb-4c12-88a1-82ef6cb430d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
